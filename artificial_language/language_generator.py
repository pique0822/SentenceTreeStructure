import argparse
import random

#python3 language_generator.py --rule_file language_rules/a2bcd_all.rul --generate_file --file_numlines 1000 --file_lenlines 100 --file_name datasets/a2bcd_all_testing.txt

parser = argparse.ArgumentParser(description='Constructed Language Generator')
parser.add_argument('--rule_file', type=str, default='language_rules/a2b.rul',
                    help='File path to .rul file that describes how to generate language corpus.')
parser.add_argument('--generate_example',type=bool, default=False,
                    help='Flag that generates an example sentence from this ruleset.')
parser.add_argument('--generate_file', action='store_true', default=False,
                    help='Flag that generates a file with {file_numlines} examples of length {file_lenlines} using this ruleset. This file is saved as {file_name}')
parser.add_argument('--file_numlines',type=int, default=10000,
                    help='This flag is only important if {generate_file} is set to True. Defines the number of lines to be generated by this rule set')
parser.add_argument('--file_lenlines',type=int, default=100,
                    help='This flag is only important if {generate_file} is set to True. Defines the number of characters to be present in each line of the dataset')
parser.add_argument('--file_name',type=str, default='generated_dataset.txt',
                    help='This flag is only important if {generate_file} is set to True. This file contians all the data generated as specified by user.')

args = parser.parse_args()

def valid_within_rules(text,ruleset):
    maximum_size_rule = min(len(sorted(ruleset.keys(),key=len,reverse=True)[0]),len(text))
    for rule_length in range(1,maximum_size_rule+1):
        for start_index in range(len(text)):
            end_index = start_index + rule_length
            sequence = text[start_index:end_index]
            if sequence in ruleset:
                correct_extension = ruleset[sequence]

                extension = text[start_index:start_index + len(ruleset[sequence])]

                if correct_extension != extension:
                    return False

    return True

def generate_example_within_rules(text_length, ruleset, vocabulary, total_attempts = 1000):
    sentence_attempts = 0
    maximum_size_rule = len(sorted(ruleset.keys(),key=len,reverse=True)[0])
    output_text = ""
    while sentence_attempts < total_attempts:
        sequence_attempts = 0
        while len(output_text) < text_length and sequence_attempts < total_attempts:
            # 1. Choose random initial sequence
                # we want to choose some seed sequence such that the seed sequence is smaller than the remaining size we have left
            seed_sequence_length = min(random.randint(1,maximum_size_rule), text_length-len(output_text))
            seed_sequence = ''.join(random.choices(vocabulary,k=seed_sequence_length))

            # 2. Check if it has a rule. If it does but it generates a replacement that is too long, try a different random character until a rule can be found or no rule comes up at all.
            if seed_sequence not in ruleset:
                output_text+=seed_sequence
                continue
            else:
                replacement = ruleset[seed_sequence]
                if len(replacement) > text_length-len(output_text):
                    sequence_attempts += 1
                    continue
                else:
                    output_text += replacement
                    continue

            sequence_attempts += 1
        if valid_within_rules(output_text,ruleset) and len(output_text) == text_length:
            return output_text
        sentence_attempts += 1

    # 3. If not text sequence can be found throw an error. Otherwise return sequence

    print('Could not generate valid text given ruleset and a text length of '+str(text_length))
    raise ValueError



vocabulary = set()
rules = {}
with open(args.rule_file) as rule_file:
    for line_idx, line in enumerate(rule_file):
        line = line.strip()
        if line_idx == 0:
            split_line = line.split('::')
            if split_line[0] != 'vocab':
                print('Ruleset ill-defined. Check line 0 has format "vocab::{V}"')
                raise ValueError
            else:
                elements = split_line[1].replace('}','').replace('{','').strip().split(',')

                vocabulary = set(elements)
        elif line_idx > 0:
            if '$' in line:
                # required follow-up rule
                previous,follows = line.split('$')
                rules[previous] = previous+follows
            else:
                print('Ruleset ill-defined. Check line '+str(line_idx)+' has format key$follow')
                raise ValueError

vocabulary_as_list = list(vocabulary)


if args.generate_example:

    print('EXAMPLE FROM RULE SET ::',generate_example_within_rules(text_length=20, ruleset=rules, vocabulary=vocabulary_as_list, total_attempts = 1000))

if args.generate_file:
    with open(args.file_name,'w+') as gen_file:
        for index in range(args.file_numlines):
            line = generate_example_within_rules(text_length=args.file_lenlines, ruleset=rules, vocabulary=vocabulary_as_list, total_attempts = 1000)
            gen_file.write(line+'\n')
